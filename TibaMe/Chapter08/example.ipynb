{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 29\n",
      "Trainable params: 29\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7043 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.7041 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.7038 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.7035 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.7033 - accuracy: 0.2500\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.7030 - accuracy: 0.2500\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.7027 - accuracy: 0.2500\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.7025 - accuracy: 0.2500\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.7022 - accuracy: 0.2500\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.7019 - accuracy: 0.2500\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.7017 - accuracy: 0.2500\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.7014 - accuracy: 0.2500\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.7012 - accuracy: 0.2500\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.7010 - accuracy: 0.2500\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.7008 - accuracy: 0.2500\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.7006 - accuracy: 0.2500\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.7004 - accuracy: 0.2500\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.7003 - accuracy: 0.2500\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.7001 - accuracy: 0.2500\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6999 - accuracy: 0.2500\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6998 - accuracy: 0.2500\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6996 - accuracy: 0.2500\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6995 - accuracy: 0.2500\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.6993 - accuracy: 0.2500\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6992 - accuracy: 0.2500\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6991 - accuracy: 0.2500\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6989 - accuracy: 0.2500\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.6988 - accuracy: 0.2500\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6986 - accuracy: 0.2500\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6985 - accuracy: 0.2500\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6984 - accuracy: 0.2500\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.6983 - accuracy: 0.2500\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6981 - accuracy: 0.2500\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6980 - accuracy: 0.2500\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6979 - accuracy: 0.2500\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6978 - accuracy: 0.2500\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6977 - accuracy: 0.2500\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6975 - accuracy: 0.2500\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6974 - accuracy: 0.2500\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6973 - accuracy: 0.2500\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6972 - accuracy: 0.2500\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6971 - accuracy: 0.2500\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6970 - accuracy: 0.2500\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6969 - accuracy: 0.2500\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.6968 - accuracy: 0.2500\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.6967 - accuracy: 0.2500\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6966 - accuracy: 0.2500\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.6965 - accuracy: 0.2500\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6964 - accuracy: 0.2500\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6963 - accuracy: 0.2500\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6962 - accuracy: 0.2500\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6961 - accuracy: 0.2500\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6961 - accuracy: 0.2500\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6960 - accuracy: 0.2500\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.6959 - accuracy: 0.2500\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6958 - accuracy: 0.2500\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6957 - accuracy: 0.2500\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6957 - accuracy: 0.2500\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6956 - accuracy: 0.2500\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6955 - accuracy: 0.2500\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6954 - accuracy: 0.2500\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6954 - accuracy: 0.2500\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6953 - accuracy: 0.2500\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.6952 - accuracy: 0.2500\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 497us/step - loss: 0.6952 - accuracy: 0.2500\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6951 - accuracy: 0.2500\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6950 - accuracy: 0.2500\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6950 - accuracy: 0.2500\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6949 - accuracy: 0.2500\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6948 - accuracy: 0.2500\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6948 - accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.6947 - accuracy: 0.2500\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6947 - accuracy: 0.2500\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6946 - accuracy: 0.2500\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.6946 - accuracy: 0.2500\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6945 - accuracy: 0.2500\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6945 - accuracy: 0.2500\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6944 - accuracy: 0.2500\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.6944 - accuracy: 0.2500\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6943 - accuracy: 0.2500\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.2500\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.2500\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.6942 - accuracy: 0.2500\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.6941 - accuracy: 0.2500\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6941 - accuracy: 0.2500\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6940 - accuracy: 0.2500\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.6940 - accuracy: 0.2500\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.6940 - accuracy: 0.2500\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6939 - accuracy: 0.2500\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6939 - accuracy: 0.2500\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6938 - accuracy: 0.2500\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6938 - accuracy: 0.2500\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6938 - accuracy: 0.2500\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6937 - accuracy: 0.2500\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6937 - accuracy: 0.2500\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6936 - accuracy: 0.2500\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6936 - accuracy: 0.2500\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6936 - accuracy: 0.2500\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6935 - accuracy: 0.2500\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6935 - accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "#preparing data for Exclusive OR (XOR)\n",
    "\n",
    "attributes = [\n",
    "    #x1, x2\n",
    "    [0 ,0]\n",
    "  , [0, 1]\n",
    "  , [1, 0]\n",
    "  , [1, 1]\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    #is_0, is_1 -> only a column can be 1 in labels variable\n",
    "    [1, 0] \n",
    "  , [0, 1]\n",
    "  , [0, 1]\n",
    "  , [1, 0]\n",
    "]\n",
    "\n",
    "#transforming attributes and labels matrixes to numpy\n",
    "data = np.array(attributes, 'int64')\n",
    "target = np.array(labels, 'int64')\n",
    "\n",
    "\n",
    "# creating model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "#  input layer to 1st hidden layer\n",
    "model.add(Dense(units=3 , input_shape=(2,))) #num of features in input layer\n",
    "\n",
    "# Dense default setting:\n",
    "# kernel_initializer='glorot_uniform', bias_initializer='zeros'\n",
    "# common kernel_initializer: 'glorot_uniform'/\n",
    "\n",
    "model.add(Activation('relu')) #activation function from input layer to 1st hidden layer\n",
    "# common activation: 'relu'/'sigmoid'/'tanh'/'LeakyReLU'\n",
    "\n",
    "# 1st hidden layer to 2end hidden layer\n",
    "model.add(Dense(units=3))\n",
    "model.add(Activation('relu')) #activation function from 1st hidden layer to 2end hidden layer\n",
    "\n",
    "\n",
    "# 2end hidden layer to output layer\n",
    "model.add(Dense(units=2)) # num of classes in output layer\n",
    "model.add(Activation('softmax')) # activation function from 2end hidden layer to output layer\n",
    "\n",
    "# summary model\n",
    "model.summary()\n",
    "\n",
    "#compile\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# different setting on compile\n",
    "# loss='mean_squared_error'/'categorical_crossentropy'/'binary_crossentropy'\n",
    "# optimizer='sgd'/'adam'/'rmsprop'\n",
    "# metrics='accuracy'/'mse'\n",
    "\n",
    "#training\n",
    "score = model.fit(data, target, epochs=100)\n",
    "#verbose: 0, 1 或 2。日志显示模式。 0 = 安静模式, 1 = 进度条, 2 = 每轮一行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function:  \n",
    "binary_crossentropy (2 classes)  \n",
    "categorical_crossentropy (>2 classes)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "MNIST is a computer vision dataset. It consists of black and white images from zero to nine. Each image is 28 * 28 and have been flatten to 784 dimension vector. Also, it includes labels for each image, telling us which digit it is.\n",
    "\n",
    "![Alt text](./images/dnn_implement/Selection_017.png)\n",
    "![Alt text](./images/dnn_implement/Selection_018.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset - training and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "print(train_images[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[0])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 59,850\n",
      "Trainable params: 59,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 4s 77us/step - loss: 0.3004 - accuracy: 0.9104 - val_loss: 0.1679 - val_accuracy: 0.9516\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 80us/step - loss: 0.1350 - accuracy: 0.9597 - val_loss: 0.1252 - val_accuracy: 0.9641\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.0971 - accuracy: 0.9709 - val_loss: 0.1165 - val_accuracy: 0.9638\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.0762 - accuracy: 0.9760 - val_loss: 0.1086 - val_accuracy: 0.9666\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.0608 - accuracy: 0.9804 - val_loss: 0.1205 - val_accuracy: 0.9669\n"
     ]
    }
   ],
   "source": [
    "# Normalize the images.\n",
    "train_images = (train_images / 255)\n",
    "test_images = (test_images / 255)\n",
    "\n",
    "# Flatten the images.\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))\n",
    "\n",
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(64, activation='relu', input_shape=(784,)),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Summary model\n",
    "model.summary()\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "train_history = model.fit(\n",
    "  x=train_images,\n",
    "  y=to_categorical(train_labels),\n",
    "  validation_split=0.2,\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history.history['loss'])  \n",
    "plt.plot(train_history.history['val_loss'])  \n",
    "plt.title('Train History')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/step\n",
      "test accuracy is 0.9704999923706055\n",
      "[7 2 1 0 4]\n",
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "test_loss, test_acc = model.evaluate(test_images, to_categorical(test_labels))\n",
    "\n",
    "print('test accuracy is {}'.format(test_acc))\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_images[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labels[:5]) # [7, 2, 1, 0, 4]'''\n",
    "\n",
    "# Save the model to disk.\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset - load model and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 34us/step\n",
      "test accuracy is 0.9704999923706055\n",
      "[7 2 1 0 4]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "(_, _), (test_images, test_labels) = mnist.load_data() # (_, _), 代表不重要的變數也可以設成常見的i, j之類\n",
    "\n",
    "\n",
    "x_test = test_images.reshape((10000, 28 * 28)) \n",
    "x_test = x_test.astype('float32') / 255      \n",
    "y_test  = to_categorical(test_labels)\n",
    "\n",
    "\n",
    "model = load_model('model.h5')  \n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test) \n",
    "print('test accuracy is {}'.format(test_acc))\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(x_test[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(y_test[:5]) # [7, 2, 1, 0, 4]'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "784\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 337,674\n",
      "Trainable params: 337,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\Python_AI\\lib\\site-packages\\ipykernel_launcher.py:55: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.2972 - accuracy: 0.9082 - val_loss: 0.1308 - val_accuracy: 0.9604\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1338 - accuracy: 0.9597 - val_loss: 0.0995 - val_accuracy: 0.9690\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1021 - accuracy: 0.9693 - val_loss: 0.0901 - val_accuracy: 0.9727\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0873 - accuracy: 0.9735 - val_loss: 0.0784 - val_accuracy: 0.9773\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0767 - accuracy: 0.9775 - val_loss: 0.0814 - val_accuracy: 0.9791\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0680 - accuracy: 0.9797 - val_loss: 0.0741 - val_accuracy: 0.9808\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0632 - accuracy: 0.9811 - val_loss: 0.0799 - val_accuracy: 0.9802\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0564 - accuracy: 0.9830 - val_loss: 0.0700 - val_accuracy: 0.9832\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0528 - accuracy: 0.9841 - val_loss: 0.0747 - val_accuracy: 0.9827\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0506 - accuracy: 0.9842 - val_loss: 0.0789 - val_accuracy: 0.9815\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0472 - accuracy: 0.9862 - val_loss: 0.0851 - val_accuracy: 0.9817\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0442 - accuracy: 0.9875 - val_loss: 0.0863 - val_accuracy: 0.9823\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0420 - accuracy: 0.9879 - val_loss: 0.0872 - val_accuracy: 0.9823\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0406 - accuracy: 0.9881 - val_loss: 0.0876 - val_accuracy: 0.9834\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0419 - accuracy: 0.9881 - val_loss: 0.0875 - val_accuracy: 0.9823\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0363 - accuracy: 0.9893 - val_loss: 0.1080 - val_accuracy: 0.9801\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0360 - accuracy: 0.9896 - val_loss: 0.0989 - val_accuracy: 0.9826\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 0.1011 - val_accuracy: 0.9819\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0349 - accuracy: 0.9901 - val_loss: 0.1035 - val_accuracy: 0.9816\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0353 - accuracy: 0.9902 - val_loss: 0.1000 - val_accuracy: 0.9820\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "Test score: 0.10001940851063365\n",
      "Test accuracy: 0.9819999933242798\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 20\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "print(X_train.shape[1])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "# add dropout\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "# add dropout\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10)) # 輸出 10 類 0~9\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('Train History')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 6us/step\n",
      "[  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
      "   3.9769    4.      307.       21.      396.9      18.72   ]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.2\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(8, activation='relu', input_shape=[X_train.shape[1]]))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/100\n",
      "323/323 [==============================] - 0s 694us/step - loss: 591.8293 - mae: 22.6116 - val_loss: 654.3442 - val_mae: 23.9187\n",
      "Epoch 2/100\n",
      "323/323 [==============================] - 0s 87us/step - loss: 580.2682 - mae: 22.3572 - val_loss: 644.7691 - val_mae: 23.7223\n",
      "Epoch 3/100\n",
      "323/323 [==============================] - 0s 65us/step - loss: 570.9208 - mae: 22.1559 - val_loss: 635.9067 - val_mae: 23.5414\n",
      "Epoch 4/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 562.1471 - mae: 21.9668 - val_loss: 626.8533 - val_mae: 23.3566\n",
      "Epoch 5/100\n",
      "323/323 [==============================] - 0s 71us/step - loss: 553.2818 - mae: 21.7748 - val_loss: 617.2855 - val_mae: 23.1623\n",
      "Epoch 6/100\n",
      "323/323 [==============================] - 0s 62us/step - loss: 543.9507 - mae: 21.5784 - val_loss: 607.3671 - val_mae: 22.9594\n",
      "Epoch 7/100\n",
      "323/323 [==============================] - 0s 65us/step - loss: 534.2318 - mae: 21.3706 - val_loss: 597.9489 - val_mae: 22.7637\n",
      "Epoch 8/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 524.6688 - mae: 21.1662 - val_loss: 586.7110 - val_mae: 22.5317\n",
      "Epoch 9/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 513.6946 - mae: 20.9288 - val_loss: 574.8627 - val_mae: 22.2844\n",
      "Epoch 10/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 502.0994 - mae: 20.6795 - val_loss: 563.1210 - val_mae: 22.0353\n",
      "Epoch 11/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 490.2500 - mae: 20.4238 - val_loss: 549.9376 - val_mae: 21.7555\n",
      "Epoch 12/100\n",
      "323/323 [==============================] - 0s 84us/step - loss: 477.2616 - mae: 20.1405 - val_loss: 535.6163 - val_mae: 21.4479\n",
      "Epoch 13/100\n",
      "323/323 [==============================] - 0s 84us/step - loss: 463.5483 - mae: 19.8348 - val_loss: 519.7606 - val_mae: 21.1026\n",
      "Epoch 14/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 448.9826 - mae: 19.5054 - val_loss: 506.9644 - val_mae: 20.8165\n",
      "Epoch 15/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 435.8568 - mae: 19.2006 - val_loss: 491.7601 - val_mae: 20.4712\n",
      "Epoch 16/100\n",
      "323/323 [==============================] - 0s 84us/step - loss: 420.8718 - mae: 18.8465 - val_loss: 475.7145 - val_mae: 20.0969\n",
      "Epoch 17/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 405.1582 - mae: 18.4692 - val_loss: 458.3762 - val_mae: 19.6808\n",
      "Epoch 18/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 388.3909 - mae: 18.0549 - val_loss: 439.4980 - val_mae: 19.2171\n",
      "Epoch 19/100\n",
      "323/323 [==============================] - 0s 84us/step - loss: 370.8097 - mae: 17.5997 - val_loss: 422.8938 - val_mae: 18.7917\n",
      "Epoch 20/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 354.2277 - mae: 17.1606 - val_loss: 403.6101 - val_mae: 18.2802\n",
      "Epoch 21/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 335.8904 - mae: 16.6502 - val_loss: 383.3919 - val_mae: 17.7287\n",
      "Epoch 22/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 317.5429 - mae: 16.1202 - val_loss: 366.2051 - val_mae: 17.2225\n",
      "Epoch 23/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 300.4604 - mae: 15.5928 - val_loss: 346.0126 - val_mae: 16.6027\n",
      "Epoch 24/100\n",
      "323/323 [==============================] - 0s 71us/step - loss: 282.1092 - mae: 14.9935 - val_loss: 328.0932 - val_mae: 16.0283\n",
      "Epoch 25/100\n",
      "323/323 [==============================] - 0s 68us/step - loss: 264.8789 - mae: 14.4105 - val_loss: 308.4800 - val_mae: 15.3524\n",
      "Epoch 26/100\n",
      "323/323 [==============================] - 0s 65us/step - loss: 247.2727 - mae: 13.7458 - val_loss: 289.8503 - val_mae: 14.6680\n",
      "Epoch 27/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 230.1005 - mae: 13.0942 - val_loss: 271.4433 - val_mae: 13.9521\n",
      "Epoch 28/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 213.7262 - mae: 12.4599 - val_loss: 253.9640 - val_mae: 13.2697\n",
      "Epoch 29/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 198.8269 - mae: 11.8254 - val_loss: 236.7366 - val_mae: 12.5921\n",
      "Epoch 30/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 184.1869 - mae: 11.2196 - val_loss: 221.7300 - val_mae: 11.9963\n",
      "Epoch 31/100\n",
      "323/323 [==============================] - 0s 71us/step - loss: 171.4162 - mae: 10.6462 - val_loss: 207.8676 - val_mae: 11.4595\n",
      "Epoch 32/100\n",
      "323/323 [==============================] - 0s 72us/step - loss: 159.7232 - mae: 10.1199 - val_loss: 195.5591 - val_mae: 10.9929\n",
      "Epoch 33/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 149.7805 - mae: 9.6244 - val_loss: 183.5295 - val_mae: 10.5328\n",
      "Epoch 34/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 140.5981 - mae: 9.1864 - val_loss: 173.4135 - val_mae: 10.2077\n",
      "Epoch 35/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 133.1879 - mae: 8.8199 - val_loss: 167.1434 - val_mae: 9.9816\n",
      "Epoch 36/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 127.6186 - mae: 8.5344 - val_loss: 160.1801 - val_mae: 9.7340\n",
      "Epoch 37/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 121.9876 - mae: 8.2857 - val_loss: 152.7517 - val_mae: 9.4545\n",
      "Epoch 38/100\n",
      "323/323 [==============================] - 0s 68us/step - loss: 116.5117 - mae: 8.0150 - val_loss: 145.9616 - val_mae: 9.1994\n",
      "Epoch 39/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 111.3676 - mae: 7.7534 - val_loss: 140.8692 - val_mae: 8.9906\n",
      "Epoch 40/100\n",
      "323/323 [==============================] - 0s 84us/step - loss: 107.0003 - mae: 7.5543 - val_loss: 135.4287 - val_mae: 8.7719\n",
      "Epoch 41/100\n",
      "323/323 [==============================] - 0s 68us/step - loss: 102.6126 - mae: 7.3550 - val_loss: 130.2051 - val_mae: 8.5462\n",
      "Epoch 42/100\n",
      "323/323 [==============================] - 0s 84us/step - loss: 98.3368 - mae: 7.1669 - val_loss: 124.3406 - val_mae: 8.3085\n",
      "Epoch 43/100\n",
      "323/323 [==============================] - 0s 87us/step - loss: 93.8352 - mae: 6.9599 - val_loss: 118.5680 - val_mae: 8.0718\n",
      "Epoch 44/100\n",
      "323/323 [==============================] - 0s 84us/step - loss: 89.6065 - mae: 6.7717 - val_loss: 113.6876 - val_mae: 7.8474\n",
      "Epoch 45/100\n",
      "323/323 [==============================] - 0s 84us/step - loss: 86.0604 - mae: 6.6083 - val_loss: 108.7218 - val_mae: 7.6478\n",
      "Epoch 46/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 82.5547 - mae: 6.4602 - val_loss: 104.4715 - val_mae: 7.4373\n",
      "Epoch 47/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 79.2255 - mae: 6.2939 - val_loss: 99.7177 - val_mae: 7.2245\n",
      "Epoch 48/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 75.9984 - mae: 6.1566 - val_loss: 96.2219 - val_mae: 7.0513\n",
      "Epoch 49/100\n",
      "323/323 [==============================] - 0s 84us/step - loss: 73.4149 - mae: 6.0122 - val_loss: 92.6223 - val_mae: 6.8761\n",
      "Epoch 50/100\n",
      "323/323 [==============================] - 0s 87us/step - loss: 70.9327 - mae: 5.8777 - val_loss: 88.4520 - val_mae: 6.6521\n",
      "Epoch 51/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 68.2754 - mae: 5.7462 - val_loss: 85.4735 - val_mae: 6.5045\n",
      "Epoch 52/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 66.1562 - mae: 5.6263 - val_loss: 82.1540 - val_mae: 6.3267\n",
      "Epoch 53/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 63.9454 - mae: 5.5049 - val_loss: 79.3996 - val_mae: 6.1840\n",
      "Epoch 54/100\n",
      "323/323 [==============================] - 0s 84us/step - loss: 61.9566 - mae: 5.3879 - val_loss: 77.0880 - val_mae: 6.0477\n",
      "Epoch 55/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 59.9885 - mae: 5.2675 - val_loss: 74.2824 - val_mae: 5.9105\n",
      "Epoch 56/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 58.1428 - mae: 5.1725 - val_loss: 71.6968 - val_mae: 5.7798\n",
      "Epoch 57/100\n",
      "323/323 [==============================] - 0s 87us/step - loss: 56.3367 - mae: 5.0579 - val_loss: 69.0941 - val_mae: 5.6838\n",
      "Epoch 58/100\n",
      "323/323 [==============================] - 0s 87us/step - loss: 54.9822 - mae: 4.9909 - val_loss: 66.9700 - val_mae: 5.5682\n",
      "Epoch 59/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 53.3839 - mae: 4.8814 - val_loss: 64.5777 - val_mae: 5.4564\n",
      "Epoch 60/100\n",
      "323/323 [==============================] - 0s 84us/step - loss: 51.9338 - mae: 4.7998 - val_loss: 62.7049 - val_mae: 5.3749\n",
      "Epoch 61/100\n",
      "323/323 [==============================] - 0s 87us/step - loss: 50.5678 - mae: 4.7189 - val_loss: 60.9130 - val_mae: 5.2937\n",
      "Epoch 62/100\n",
      "323/323 [==============================] - 0s 65us/step - loss: 49.2494 - mae: 4.6355 - val_loss: 59.1054 - val_mae: 5.2229\n",
      "Epoch 63/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 47.9616 - mae: 4.5627 - val_loss: 57.7327 - val_mae: 5.1565\n",
      "Epoch 64/100\n",
      "323/323 [==============================] - 0s 99us/step - loss: 46.8491 - mae: 4.4941 - val_loss: 56.0779 - val_mae: 5.0739\n",
      "Epoch 65/100\n",
      "323/323 [==============================] - 0s 65us/step - loss: 45.6420 - mae: 4.4123 - val_loss: 54.5346 - val_mae: 4.9874\n",
      "Epoch 66/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 44.5255 - mae: 4.3368 - val_loss: 52.7829 - val_mae: 4.8994\n",
      "Epoch 67/100\n",
      "323/323 [==============================] - 0s 65us/step - loss: 43.4480 - mae: 4.2743 - val_loss: 51.2191 - val_mae: 4.8268\n",
      "Epoch 68/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 42.3398 - mae: 4.2122 - val_loss: 50.6978 - val_mae: 4.7986\n",
      "Epoch 69/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 41.5821 - mae: 4.1695 - val_loss: 49.1125 - val_mae: 4.7127\n",
      "Epoch 70/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 40.6895 - mae: 4.1117 - val_loss: 48.6210 - val_mae: 4.6880\n",
      "Epoch 71/100\n",
      "323/323 [==============================] - 0s 68us/step - loss: 39.7776 - mae: 4.0560 - val_loss: 47.3736 - val_mae: 4.6189\n",
      "Epoch 72/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 38.9279 - mae: 4.0041 - val_loss: 46.8484 - val_mae: 4.5924\n",
      "Epoch 73/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 38.3357 - mae: 3.9608 - val_loss: 45.9414 - val_mae: 4.5600\n",
      "Epoch 74/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 37.5911 - mae: 3.9143 - val_loss: 45.0332 - val_mae: 4.5183\n",
      "Epoch 75/100\n",
      "323/323 [==============================] - 0s 71us/step - loss: 36.8471 - mae: 3.8719 - val_loss: 44.2304 - val_mae: 4.4852\n",
      "Epoch 76/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 36.0135 - mae: 3.8201 - val_loss: 43.4111 - val_mae: 4.4446\n",
      "Epoch 77/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 35.2271 - mae: 3.7832 - val_loss: 42.4816 - val_mae: 4.4011\n",
      "Epoch 78/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 34.3319 - mae: 3.7220 - val_loss: 41.5625 - val_mae: 4.3655\n",
      "Epoch 79/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 33.5794 - mae: 3.6806 - val_loss: 40.6378 - val_mae: 4.3192\n",
      "Epoch 80/100\n",
      "323/323 [==============================] - 0s 71us/step - loss: 32.8619 - mae: 3.6453 - val_loss: 39.6707 - val_mae: 4.2748\n",
      "Epoch 81/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 32.0870 - mae: 3.6115 - val_loss: 39.0479 - val_mae: 4.2447\n",
      "Epoch 82/100\n",
      "323/323 [==============================] - 0s 84us/step - loss: 31.5247 - mae: 3.6023 - val_loss: 38.0999 - val_mae: 4.2008\n",
      "Epoch 83/100\n",
      "323/323 [==============================] - 0s 71us/step - loss: 30.8751 - mae: 3.5640 - val_loss: 36.8965 - val_mae: 4.1486\n",
      "Epoch 84/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 30.2962 - mae: 3.5489 - val_loss: 36.5105 - val_mae: 4.1331\n",
      "Epoch 85/100\n",
      "323/323 [==============================] - 0s 62us/step - loss: 29.8949 - mae: 3.5281 - val_loss: 35.8333 - val_mae: 4.1004\n",
      "Epoch 86/100\n",
      "323/323 [==============================] - 0s 71us/step - loss: 29.4843 - mae: 3.5034 - val_loss: 35.0458 - val_mae: 4.0585\n",
      "Epoch 87/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 28.9804 - mae: 3.4797 - val_loss: 34.2786 - val_mae: 4.0214\n",
      "Epoch 88/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 28.4840 - mae: 3.4383 - val_loss: 33.6976 - val_mae: 3.9895\n",
      "Epoch 89/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 27.9059 - mae: 3.3969 - val_loss: 32.8881 - val_mae: 3.9522\n",
      "Epoch 90/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 27.4707 - mae: 3.3866 - val_loss: 32.1708 - val_mae: 3.9214\n",
      "Epoch 91/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 26.9377 - mae: 3.3763 - val_loss: 31.5846 - val_mae: 3.8917\n",
      "Epoch 92/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 26.5494 - mae: 3.3514 - val_loss: 31.2611 - val_mae: 3.8805\n",
      "Epoch 93/100\n",
      "323/323 [==============================] - 0s 62us/step - loss: 26.1328 - mae: 3.3100 - val_loss: 30.5177 - val_mae: 3.8403\n",
      "Epoch 94/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 25.7594 - mae: 3.3005 - val_loss: 29.9192 - val_mae: 3.8001\n",
      "Epoch 95/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 25.3922 - mae: 3.2864 - val_loss: 29.4279 - val_mae: 3.7731\n",
      "Epoch 96/100\n",
      "323/323 [==============================] - 0s 71us/step - loss: 25.0672 - mae: 3.2644 - val_loss: 28.8142 - val_mae: 3.7391\n",
      "Epoch 97/100\n",
      "323/323 [==============================] - 0s 87us/step - loss: 24.6150 - mae: 3.2343 - val_loss: 28.1219 - val_mae: 3.7102\n",
      "Epoch 98/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 24.2460 - mae: 3.2142 - val_loss: 27.7556 - val_mae: 3.6813\n",
      "Epoch 99/100\n",
      "323/323 [==============================] - 0s 84us/step - loss: 23.9277 - mae: 3.1953 - val_loss: 27.2814 - val_mae: 3.6472\n",
      "Epoch 100/100\n",
      "323/323 [==============================] - 0s 81us/step - loss: 23.6618 - mae: 3.1690 - val_loss: 26.6254 - val_mae: 3.6207\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history = model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 49us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[27.78503148696002, 4.09093713760376]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test) # MSE & MAE\n",
    "# output values represent the loss(MSE) and the metrics(MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.933854]\n",
      " [17.022379]]\n"
     ]
    }
   ],
   "source": [
    "to_predict = X_test_scaled[:2]\n",
    "predictions = model.predict(to_predict)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.2 18.8]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "參考 dnn network playground - 體驗DNN演示平臺\n",
    "\n",
    "https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.09778&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
